{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Regression | Assignment questions***\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "OmMKRek5tWIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques1.  What is Simple Linear Regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: By term Regression - establish a relationship between two or more varibales, Linear - establish a linear relationship. Simple Linear Regression attempts to determine the strength and characteristics of relationship between one independent variable (x) and another dependent variable (y).\n",
        "\n"
      ],
      "metadata": {
        "id": "I1qls9FCtdfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: The key assumptions of Simple Linear Regression are:\n",
        "- Linearity: The relationship between the independent variable (X) and dependent variable (Y) is linear.\n",
        "- Independence: The residuals (errors) are independent of each other; no autocorrelation exists.\n",
        "- Homoscedasticity: The residuals have constant variance across all values of X.\n",
        "- Normality of Residuals: The residuals are normally distributed, especially important for hypothesis testing.\n",
        "- The independent variable is assumed to be measured accurately.\n",
        "\n"
      ],
      "metadata": {
        "id": "eU_fq2zqfLFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques3.  What does the coefficient m represent in the equation Y=mX+c?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: The coefficient m represents slope of line, it shows rate of change of dependent variable with respect to independent variable.\n"
      ],
      "metadata": {
        "id": "2djQ09oVf-5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques4. What does the intercept c represent in the equation Y=mX+c?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: The intercept c is the constant term that anchors the line on the Y-axis, showing the value of Y when X is zero.\n",
        "\n"
      ],
      "metadata": {
        "id": "JuX4fLZDgdW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques5. How do we calculate the slope m in Simple Linear Regression?\n",
        "\n",
        "\n",
        "---\n",
        "Formula to calculate slope,\n",
        "m = ùû¢((xi - xmean)(yi - ymean)) / ùû¢(xi - xmean)^2\n",
        "\n"
      ],
      "metadata": {
        "id": "c7uLDq20hDKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques6.  What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: The least squares method in simple linear regression is used to find the line of best fit by minimizing the sum of squared differences between actual values and predicted values."
      ],
      "metadata": {
        "id": "lXsVm5iaklIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques7.  How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: The coefficient of determination (R¬≤) in simple linear regression tells us how well the regression line explains the variation in the dependent variable Y."
      ],
      "metadata": {
        "id": "DqGSsqTw-BUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques8. What is Multiple Linear Regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: By term Multiple it means multiple variable.So, Multiple Linear Regression attempts to determine the strength and characteristics of relationship between multiple features.\n"
      ],
      "metadata": {
        "id": "YrJ-3p6j-WU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: The main difference is SLR deals with only one independent variable while MLR deals with multiple variables.\n"
      ],
      "metadata": {
        "id": "Gm2tF2Oe-unu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques10.  What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: The key assumptions of Multiple Linear Regression are:\n",
        "- Linearity: relationship between predictors and outcome is linear\n",
        "- Independence: errors are independent\n",
        "- Homoscedasticity: constant variance of errors\n",
        "- Normality: errors are normally distributed\n",
        "- No perfect multicollinearity: predictors are not highly correlated\n"
      ],
      "metadata": {
        "id": "bflj0vVd--4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques11.  What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model.\n",
        "\n",
        "\n",
        "---\n",
        "Ans: Heteroscedasticity means the residuals (errors) in a regression model have unequal variance.It does not bias the coefficients, but it makes standard errors unreliable, leading to invalid hypothesis tests and confidence intervals.\n",
        "\n"
      ],
      "metadata": {
        "id": "IrCAcSZA_O5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques12.  How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: To improve a regression model with high multicollinearity:\n",
        "- Drop or combine highly correlated predictors\n",
        "- Use Ridge or Lasso Regression\n",
        "- Apply PCA to create uncorrelated components\n",
        "- Check and reduce variables with high VIF\n",
        "\n"
      ],
      "metadata": {
        "id": "RKUtGE-K_nCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques13.  What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: Common techniques to transform categorical variables for regression are:\n",
        "- One-Hot/Dummy Encoding ‚Üí create binary columns for categories\n",
        "- Label Encoding ‚Üí assign numeric codes\n",
        "- Ordinal Encoding ‚Üí map ordered categories to numbers\n",
        "- Target/Mean Encoding ‚Üí replace categories with target averages"
      ],
      "metadata": {
        "id": "2u3aJH8N_4Zm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques14. - What is the role of interaction terms in Multiple Linear Regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: The role of interaction terms in Multiple Linear Regression is to capture situations where the effect of one independent variable on the dependent variable depends on the level of another variable.\n"
      ],
      "metadata": {
        "id": "iDeCehxJAHUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques15.  How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: In Simple Linear Regression, it is the expected value of Y when X=0.In Multiple Linear Regression, it is the expected value of Y when all predictors= 0, which may not always be meaningful.\n",
        "\n"
      ],
      "metadata": {
        "id": "eMA34k4ZA1JV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 16.What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: The slope measures the rate of change in Y with respect to X, directly controlling how predictions move when X changes.It shows how much the dependent variable (Y) changes for a one-unit increase in the independent variable (X).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qBYaY6boBNi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: In a regression model, the intercept is the value of the dependent variable (Y) when all independent variables (X) are equal to zero.Example: If you regress house price on square footage, the intercept might represent the predicted price of a house with 0 square feet ‚Äî not realistic, but still necessary for the equation.\n",
        "\n"
      ],
      "metadata": {
        "id": "-63j0dL1BhWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques18. What are the limitations of using R¬≤ as a sole measure of model performance?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: Limitations of using R^2:\n",
        "- Does not prove causality - only shows correlation.\n",
        "- Always increases with more predictors - risk of overfitting.\n",
        "- No info on prediction accuracy - ignores bias and error size.\n",
        "- Does not check assumptions - residual patterns may still be wrong.\n",
        "- Not comparable across different dependent variables.\n",
        "- Misleading for nonlinear models - fit quality is not captured well.\n",
        "- R^2 is just a fit indicator, not a full performance measure."
      ],
      "metadata": {
        "id": "ZqqVMNsLT_Eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques19.  How would you interpret a large standard error for a regression coefficient?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: It signals the coefficient is unreliable and its true impact is unclear.\n",
        "\n"
      ],
      "metadata": {
        "id": "MCk-azLGUz1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: Heteroscedasticity shows up as uneven spread of residuals in plots, and fixing it matters because it protects the accuracy of tests, confidence intervals, and predictions."
      ],
      "metadata": {
        "id": "IQroP-U1VGIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques21. What does it mean if a Multiple Linear Regression model has a high R¬≤ but low adjusted R¬≤?\n",
        "\n",
        "\n",
        "---\n",
        "Ans:- This usually indicates:\n",
        "- Overfitting: Too many variables included, some of which are just noise.\n",
        "- Irrelevant predictors: Variables that don‚Äôt contribute meaningfully to prediction.\n",
        "- Small sample size relative to predictors: Adjusted R¬≤ punishes models more harshly when the dataset is small but the number of predictors is large.\n"
      ],
      "metadata": {
        "id": "jvnuTY5vYJ5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: Scaling variables in multiple linear regression is important because it improves numerical stability, makes coefficients comparable, ensures fair regularization penalties, and speeds up optimization convergence.\n",
        "\n"
      ],
      "metadata": {
        "id": "RfqP32ziWJAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques23. What is polynomial regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: Polynomial regression is a type of regression analysis that models the relationship between variables using a polynomial equation, allowing curved (non-linear) patterns to be captured instead of just straight lines.\n"
      ],
      "metadata": {
        "id": "JMCKID0qWbtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques24. How does polynomial regression differ from linear regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans:\n",
        "- Linear regression ‚Üí fits a straight line (y=a0+a1x)\n",
        "- Polynomial regression ‚Üí fits a curved line (y=a0+a1x+a2x^2+.....)\n",
        "- Linear ‚Üí captures linear relationships\n",
        "- Polynomial ‚Üí captures non-linear relationships\n",
        "- Linear ‚Üí simple, easy to interpret\n",
        "- Polynomial ‚Üí flexible, but risk of overfitting\n"
      ],
      "metadata": {
        "id": "Eyl0oRrhWruj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques25. When is polynomial regression used?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: Polynomial regression is used when data shows a non-linear relationship, and a straight line (linear regression) cannot capture the curved trend effectively."
      ],
      "metadata": {
        "id": "_KBxauOWXKce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques26.  What is the general equation for polynomial regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans:The general equation for polynomial regression is:\n",
        "\n",
        " `y = a0 + a1x + a2x^2 + a3x^3+....+anx^n`\n",
        "\n",
        "where a_0,a_1,\\dots ,a_n are coefficients, n is the degree of the polynomial, and \\epsilon  is the error term.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xBfBnvi0XcPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques27. Can polynomial regression be applied to multiple variables?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: Yes, polynomial regression can be applied to multiple variables also called multivariate polynomial regression.\n",
        "\n"
      ],
      "metadata": {
        "id": "NyeZUer35IUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques28.  What are the limitations of polynomial regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans:\n",
        "- Overfitting: Higher-degree polynomials fit noise, not just the trend.\n",
        "- Multicollinearity: Polynomial terms are highly correlated, making coefficients unstable.\n",
        "- Complexity: Number of features grows fast with degree and variables.\n",
        "- Scaling issues: Large values from powers can cause instability.\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZN8IGvh7ci7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques29.  What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "\n",
        "\n",
        "---\n",
        "Ans:To evaluate model fit when choosing the degree of a polynomial, you should balance accuracy with complexity using metrics like R¬≤/adjusted R¬≤, residual analysis, cross-validation, and information criteria (AIC/BIC)."
      ],
      "metadata": {
        "id": "oLJk7PUK78Na"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques30.Why is visualization important in polynomial regression?\n",
        "\n",
        "\n",
        "---\n",
        "Ans: Visualization in polynomial regression is important because it:\n",
        "- Shows underfitting vs. overfitting clearly.\n",
        "- Reveals how the curve behaves across data.\n",
        "- Makes results easier to explain to others.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6UmtQSbk8Xj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques31. How is polynomial regression implemented in Python?\n",
        "\n",
        "\n",
        "---\n",
        "Ans:Example to implement polynomial regression:\n",
        "\n",
        "\n",
        "```\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "\n",
        "X_poly_train = poly_features.fit_transform(X_train)\n",
        "\n",
        "poly_reg = LinearRegression()\n",
        "poly_reg.fit(X_poly_train,y_train)\n",
        "\n",
        "poly_reg.coef_ , poly_reg.intercept_\n",
        "\n",
        "poly_reg.predict(X_poly_train)\n",
        "```\n",
        "Above example shows to implement polynomial regression in python use PolynomialFeatures from sklearn.preprocessing module.\n"
      ],
      "metadata": {
        "id": "Clo2FwnX8tJ6"
      }
    }
  ]
}